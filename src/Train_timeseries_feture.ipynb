{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fddf607",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer, Categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e7158",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('D:\\\\NCKH - Estimation GHG\\\\Output\\\\2020\\\\data_co2_modis_soilgrid_2020.csv')\n",
    "df2 = pd.read_csv('D:\\\\NCKH - Estimation GHG\\\\Output\\\\2021\\\\data_co2_modis_soilgrid_2021.csv')\n",
    "df3 = pd.read_csv('D:\\\\NCKH - Estimation GHG\\\\Output\\\\2022\\\\data_co2_modis_soilgrid_2022.csv')\n",
    "df = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78755ea",
   "metadata": {},
   "source": [
    "### Create Time Series Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48926f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['LST_Night_Terra_C', 'LST_Night_Aqua_C', 'LST_Day_Terra_C', 'LST_Day_Aqua_C'])\n",
    "df['time'] = pd.to_datetime(df['time'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaeb84d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature chu kỳ\n",
    "df['month'] = df['time'].dt.month\n",
    "df['day_of_year'] = df['time'].dt.dayofyear\n",
    "df['day_of_week'] = df['time'].dt.dayofweek\n",
    "df['hour'] = df['time'].dt.hour\n",
    "\n",
    "# Mã hóa chu kỳ bằng sin/cos\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['dayofyear_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "df['dayofyear_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365.25)\n",
    "\n",
    "# Feature xu hướng\n",
    "df['year'] = df['time'].dt.year\n",
    "df['time_idx'] = (df['time'] - df['time'].min()).dt.total_seconds() / (3600 * 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec05ecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff = df['time'].diff()  \n",
    "pass_threshold = pd.Timedelta(minutes=30)   \n",
    "df['pass_id'] = (time_diff > pass_threshold).cumsum()\n",
    "print(\"Dữ liệu sau khi gán 'pass_id':\")\n",
    "print(df[['time', 'pass_id']])\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5a501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khoảng cách Haversine (khoảng cách giữa 2 điểm trên mặt cầu)\n",
    "def haversine_distance(lon1, lat1, lon2, lat2):\n",
    "    R = 6371  \n",
    "    lon1_rad, lat1_rad, lon2_rad, lat2_rad = map(np.radians, [lon1, lat1, lon2, lat2])\n",
    "    dlon = lon2_rad - lon1_rad\n",
    "    dlat = lat2_rad - lat1_rad\n",
    "    a = np.sin(dlat / 2.0)**2 + np.cos(lat1_rad) * np.cos(lat2_rad) * np.sin(dlon / 2.0)**2\n",
    "    c = 2 * np.arcsin(np.sqrt(a))\n",
    "    return R * c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a399b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['xco2_lag_1'] = df.groupby('pass_id')['xco2'].shift(1)\n",
    "df['xco2_lag_2'] = df.groupby('pass_id')['xco2'].shift(2)\n",
    "df['xco2_lag_3'] = df.groupby('pass_id')['xco2'].shift(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f4d3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 5\n",
    "df['xco2_rolling_mean_5'] = df.groupby('pass_id')['xco2'].transform(\n",
    "    lambda x: x.rolling(window=window_size, min_periods=1).mean()\n",
    ")\n",
    "df['xco2_rolling_std_5'] = df.groupby('pass_id')['xco2'].transform(\n",
    "    lambda x: x.rolling(window=window_size, min_periods=1).std()\n",
    ")\n",
    "\n",
    "window_size = 10\n",
    "df['xco2_rolling_mean_10'] = df.groupby('pass_id')['xco2'].transform(\n",
    "    lambda x: x.rolling(window=window_size, min_periods=1).mean()\n",
    ")\n",
    "df['xco2_rolling_std_10'] = df.groupby('pass_id')['xco2'].transform(\n",
    "    lambda x: x.rolling(window=window_size, min_periods=1).std()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3dc080",
   "metadata": {},
   "source": [
    "### BASIC: Create time window, skip space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f3b355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_indexed = df.set_index('time')\n",
    "windows = ['7D', '30D']\n",
    "for window in windows:\n",
    "    rolling_xco2 = df_indexed['xco2'].rolling(window, closed='left')\n",
    "    df[f'xco2_regional_mean_{window}'] = rolling_xco2.mean().values\n",
    "    df[f'xco2_regional_std_{window}'] = rolling_xco2.std().values\n",
    "    \n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d000ec",
   "metadata": {},
   "source": [
    "### ADVANCE: Create a time-space weighted average window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25647f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_spatiotemporal_weighted_features(target_row, all_data, config):\n",
    "    \"\"\"\n",
    "    Tính toán các đặc trưng trung bình có trọng số theo không gian-thời gian.\n",
    "    \n",
    "    Args:\n",
    "        target_row: Hàng dữ liệu (điểm P) mà ta muốn tính đặc trưng.\n",
    "        all_data: Toàn bộ DataFrame chứa các điểm lân cận tiềm năng.\n",
    "        config: Dictionary chứa các tham số.\n",
    "    \n",
    "    Returns:\n",
    "        Một dictionary chứa các đặc trưng mới.\n",
    "    \"\"\"\n",
    "    p_time = target_row['time']\n",
    "    p_lat = target_row['latitude']\n",
    "    p_lon = target_row['longitude']\n",
    "    \n",
    "    # 1. Lọc các điểm lân cận trong một cửa sổ thời gian\n",
    "    past_data = all_data[\n",
    "        (all_data['time'] >= p_time - config['time_window']) & \n",
    "        (all_data['time'] < p_time)\n",
    "    ]\n",
    "    if past_data.empty:\n",
    "        return {'xco2_weighted_mean_idw': np.nan, 'xco2_weighted_mean_gaussian': np.nan}\n",
    "        \n",
    "    # 2. Tính toán khoảng cách không gian và thời gian\n",
    "    space_dist = haversine_distance(p_lon, p_lat, past_data['longitude'], past_data['latitude'])\n",
    "    time_dist_days = (p_time - past_data['time']).dt.total_seconds() / (3600 * 24)\n",
    "    values = past_data['xco2']\n",
    "    \n",
    "    # 3. Tính toán trọng số    \n",
    "    # a. Nghịch đảo Khoảng cách (IDW)\n",
    "    weight_idw = 1.0 / (space_dist * time_dist_days + config['epsilon'])\n",
    "    \n",
    "    # b. Gaussian Kernel\n",
    "    weight_space = np.exp(-(space_dist**2) / (2 * config['space_bandwidth']**2))\n",
    "    weight_time = np.exp(-(time_dist_days**2) / (2 * config['time_bandwidth']**2))\n",
    "    weight_gaussian = weight_space * weight_time\n",
    "\n",
    "    # 4. Tính toán trung bình trọng số\n",
    "    if np.sum(weight_idw) < 1e-9:\n",
    "        mean_idw = np.nan\n",
    "    else:\n",
    "        mean_idw = np.average(values, weights=weight_idw)\n",
    "        \n",
    "    if np.sum(weight_gaussian) < 1e-9:\n",
    "        mean_gaussian = np.nan\n",
    "    else:\n",
    "        mean_gaussian = np.average(values, weights=weight_gaussian)\n",
    "        \n",
    "    return {\n",
    "        'xco2_weighted_mean_idw': mean_idw,\n",
    "        'xco2_weighted_mean_gaussian': mean_gaussian\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2806fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'time_window': pd.Timedelta(days=30),\n",
    "    'epsilon': 1e-6, \n",
    "    'space_bandwidth': 20.0, \n",
    "    'time_bandwidth': 15.0, \n",
    "}\n",
    "weighted_features_df = df.apply(\n",
    "    lambda row: calculate_spatiotemporal_weighted_features(row, df, config),\n",
    "    axis=1,\n",
    "    result_type='expand'\n",
    ")\n",
    "df = pd.concat([df, weighted_features_df], axis=1)\n",
    "print(\"\\n--- DataFrame cuối cùng với đặc trưng có trọng số ---\")\n",
    "print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f75ef4",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfc7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name=\"\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"Kết quả cho {model_name}:\")\n",
    "    print(f\"  Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"  Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"  R-squared (R2): {r2:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee6f4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'xco2'\n",
    "features = [col for col in df.columns if col not in [target,'time','date', 'xco2_quality_flag','rice_proportion_in_buffer','is_rice_influenced']]\n",
    "features_to_drop_for_residual = [\n",
    "    'time_idx',\n",
    "    'year',  \n",
    "]\n",
    "trend_features = ['time_idx']\n",
    "residual_features = [f for f in features if f not in features_to_drop_for_residual]\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2083b664",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_fraction = 0.8\n",
    "split_index = int(len(df) * split_fraction)\n",
    "# train_df = df[df['date'] < '2024-01-01']\n",
    "# test_df = df[df['date'] >= '2024-01-01']\n",
    "train_df = df.iloc[:split_index]\n",
    "test_df = df.iloc[split_index:]\n",
    "\n",
    "X_train = train_df[features]\n",
    "y_train = train_df[target]\n",
    "X_test = test_df[features]\n",
    "y_test = test_df[target]\n",
    "\n",
    "X_train_trend = X_train[trend_features]\n",
    "X_test_trend = X_test[trend_features]\n",
    "X_train_residual = X_train[residual_features]\n",
    "X_test_residual = X_test[residual_features]\n",
    "\n",
    "print(f\"Kích thước tập Train: {len(X_train)} mẫu\")\n",
    "print(f\"Kích thước tập Test: {len(X_test)} mẫu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b531dd",
   "metadata": {},
   "source": [
    "### Base models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM\n",
    "lgbm = lgb.LGBMRegressor(random_state=42)\n",
    "lgbm.fit(X_train, y_train)\n",
    "lgbm_preds = lgbm.predict(X_test)\n",
    "evaluate_model(y_test, lgbm_preds, \"LightGBM cơ bản\")\n",
    "\n",
    "# XGBoost\n",
    "xgbr = xgb.XGBRegressor(random_state=42)\n",
    "xgbr.fit(X_train, y_train)\n",
    "xgbr_preds = xgbr.predict(X_test)\n",
    "evaluate_model(y_test, xgbr_preds, \"XGBoost cơ bản\")\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_preds = rf.predict(X_test)\n",
    "evaluate_model(y_test, rf_preds, \"Random Forest cơ bản\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=lgbm_preds, ax=ax, alpha=0.6, label='Predicted')\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2, label='Line (y=x)')\n",
    "m, c = np.polyfit(y_test, lgbm_preds, 1)\n",
    "ax.plot(y_test, m * y_test + c, color='blue', linewidth=2, label=f'Fit Line: y={m:.2f}x + {c:.2f}')\n",
    "r2_value = r2_score(y_test, lgbm_preds)\n",
    "ax.lines[1].set_label(f'Fit Line (R²={r2_value:.2f})')\n",
    "ax.set_xlabel(\"Actual\", fontsize=12)\n",
    "ax.set_ylabel(\"Predicted\", fontsize=12)\n",
    "ax.set_title(\"Prediction results on the test set of model LightGBM\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "770df8f0",
   "metadata": {},
   "source": [
    "### Fine-tune LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces = {\n",
    "    'num_leaves': Integer(20, 700),\n",
    "    'n_estimators': Integer(90, 700), \n",
    "    'max_depth': Integer(5, 20), \n",
    "    'learning_rate': Real(0.01, 0.5, 'log-uniform'),\n",
    "    'subsample': Real(0.5, 1.0, 'uniform'),\n",
    "    'colsample_bytree': Real(0.3, 1.0, 'uniform'), \n",
    "    'min_child_samples': Integer(5, 30),                   \n",
    "    'reg_alpha': Real(0.0, 1.0, 'uniform'),           \n",
    "    'reg_lambda': Real(0.0, 1.0, 'uniform'), \n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "lgbm_model = lgb.LGBMRegressor(random_state=42)\n",
    "bayes_search_lgbm = BayesSearchCV(\n",
    "    estimator=lgbm_model,\n",
    "    search_spaces=search_spaces, \n",
    "    n_iter=200,  \n",
    "    cv=tscv,\n",
    "    scoring='r2',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "bayes_search_lgbm.fit(X_train, y_train)\n",
    "print(f\"\\nCác tham số tốt nhất cho LightGBM (Bayesian Optimization): {bayes_search_lgbm.best_params_}\")\n",
    "best_lgbm_params = dict(bayes_search_lgbm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0a18ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lgbm = lgb.LGBMRegressor(**best_lgbm_params, random_state=42)\n",
    "final_lgbm.fit(X_train, y_train)\n",
    "final_preds_lgbm = final_lgbm.predict(X_test)\n",
    "evaluate_model(y_test, final_preds_lgbm, \"LightGBM đã tinh chỉnh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ede5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_lgbm = final_lgbm.feature_importances_\n",
    "feature_importance_lgbm = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importances_lgbm\n",
    "})\n",
    "feature_importance_xgb = feature_importance_lgbm.sort_values(by='Importance', ascending=False)\n",
    "top_n = 60\n",
    "top_features_df = feature_importance_xgb.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features_df, palette='viridis')\n",
    "plt.title(f'Top {top_n} Feature Importances', fontsize=16)\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2f0239",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=final_preds_lgbm, ax=ax, alpha=0.6, label='Predicted')\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2, label='Line (y=x)')\n",
    "m, c = np.polyfit(y_test, final_preds_lgbm, 1)\n",
    "ax.plot(y_test, m * y_test + c, color='blue', linewidth=2, label=f'Fit Line: y={m:.2f}x + {c:.2f}')\n",
    "r2_value = r2_score(y_test, final_preds_lgbm)\n",
    "ax.lines[1].set_label(f'Fit Line (R²={r2_value:.2f})')\n",
    "ax.set_xlabel(\"Actual\", fontsize=12)\n",
    "ax.set_ylabel(\"Predicted\", fontsize=12)\n",
    "ax.set_title(\"Prediction results on the test set of model LightGBM\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c06984",
   "metadata": {},
   "source": [
    "### Fine-tune XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d85d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces_xgb = {\n",
    "    'n_estimators': Integer(100, 1000),\n",
    "    'colsample_bytree': Real(0.3, 1.0, 'uniform'),\n",
    "    'gamma': Real(0.0, 1.0, 'uniform'),\n",
    "    'max_depth': Integer(6, 30),\n",
    "    'subsample': Real(0.5, 1.0, 'uniform'),\n",
    "    'reg_alpha': Real(0.0, 1.0, 'uniform'),           \n",
    "    'reg_lambda': Real(0.0, 1.0, 'uniform'),\n",
    "    'learning_rate': Real(0.01, 0.5, 'log-uniform'),                 \n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "xgb_model = xgb.XGBRegressor(random_state=42, tree_method='hist')\n",
    "bayes_search_xgb = BayesSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    search_spaces=search_spaces_xgb,\n",
    "    n_iter=200,\n",
    "    cv=tscv,\n",
    "    scoring='r2',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=1\n",
    ")\n",
    "bayes_search_xgb.fit(X_train, y_train)\n",
    "print(f\"\\nCác tham số tốt nhất cho XGBoost (Bayesian Optimization): {bayes_search_xgb.best_params_}\")\n",
    "best_xgb_params = dict(bayes_search_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b115dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_xgb = xgb.XGBRegressor(**best_xgb_params, random_state=42)\n",
    "final_xgb.fit(X_train, y_train)\n",
    "final_preds_xgb = final_xgb.predict(X_test)\n",
    "evaluate_model(y_test, final_preds_xgb, \"XGB đã tinh chỉnh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4d48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_xgb = final_xgb.feature_importances_\n",
    "feature_importance_xgb = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importances_xgb\n",
    "})\n",
    "feature_importance_xgb = feature_importance_xgb.sort_values(by='Importance', ascending=False)\n",
    "top_n = 60\n",
    "top_features_df = feature_importance_xgb.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features_df, palette='viridis')\n",
    "plt.title(f'Top {top_n} Feature Importances (Base on Gain)', fontsize=16)\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b2c97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=final_preds_xgb, ax=ax, alpha=0.6, label='Predicted')\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2, label='Line (y=x)')\n",
    "m, c = np.polyfit(y_test, final_preds_xgb, 1)\n",
    "ax.plot(y_test, m * y_test + c, color='blue', linewidth=2, label=f'Fit Line: y={m:.2f}x + {c:.2f}')\n",
    "r2_value = r2_score(y_test, final_preds_xgb)\n",
    "ax.lines[1].set_label(f'Fit Line (R²={r2_value:.2f})')\n",
    "ax.set_xlabel(\"Actual\", fontsize=12)\n",
    "ax.set_ylabel(\"Predicted\", fontsize=12)\n",
    "ax.set_title(\"Prediction results on the test set of model XGBoost\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681efbcb",
   "metadata": {},
   "source": [
    "### Fine-tune Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24eef0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces_rf = {\n",
    "    'n_estimators': Integer(100, 500),\n",
    "    'max_depth': Integer(6, 30),\n",
    "    'min_samples_split': Integer(2, 20),\n",
    "    'min_samples_leaf': Integer(1, 10),    \n",
    "    'max_features' : Real(0.5, 1.0, 'uniform'),           \n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "rf_model = RandomForestRegressor(random_state=42)\n",
    "bayes_search_rf = BayesSearchCV(\n",
    "    estimator=rf_model,\n",
    "    search_spaces=search_spaces_rf,\n",
    "    n_iter=200,\n",
    "    cv=tscv,\n",
    "    scoring='r2',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=1\n",
    ")\n",
    "bayes_search_rf.fit(X_train, y_train)\n",
    "print(f\"\\nCác tham số tốt nhất cho Random Forest (Bayesian Optimization): {bayes_search_rf.best_params_}\")\n",
    "best_rf_params = dict(bayes_search_rf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f15f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf = RandomForestRegressor(**best_rf_params, random_state=42)\n",
    "final_rf.fit(X_train, y_train)\n",
    "final_preds_rf = final_rf.predict(X_test)\n",
    "evaluate_model(y_test, final_preds_rf, \"RF đã tinh chỉnh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858131df",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_rf = final_rf.feature_importances_\n",
    "feature_importance_rf = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Importance': importances_rf\n",
    "})\n",
    "feature_importance_rf = feature_importance_rf.sort_values(by='Importance', ascending=False)\n",
    "top_n = 60\n",
    "top_features_df = feature_importance_xgb.head(top_n)\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.barplot(x='Importance', y='Feature', data=top_features_df, palette='viridis')\n",
    "plt.title(f'Top {top_n} Feature Importances (Base on Gain)', fontsize=16)\n",
    "plt.xlabel('Importance Score', fontsize=12)\n",
    "plt.ylabel('Feature', fontsize=12)\n",
    "plt.tight_layout() \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74ba6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=final_preds_rf, ax=ax, alpha=0.6, label='Predicted')\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2, label='Line (y=x)')\n",
    "m, c = np.polyfit(y_test, final_preds_rf, 1)\n",
    "ax.plot(y_test, m * y_test + c, color='blue', linewidth=2, label=f'Fit Line: y={m:.2f}x + {c:.2f}')\n",
    "r2_value = r2_score(y_test, final_preds_rf)\n",
    "ax.lines[1].set_label(f'Fit Line (R²={r2_value:.2f})')\n",
    "ax.set_xlabel(\"Actual\", fontsize=12)\n",
    "ax.set_ylabel(\"Predicted\", fontsize=12)\n",
    "ax.set_title(\"Prediction results on the test set of model Random Forest\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683ac0a7",
   "metadata": {},
   "source": [
    "### Fine-tune SVR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910dff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09963d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_spaces_svr = {\n",
    "    'C': Real(1e-1, 1e+3, 'log-uniform'), \n",
    "    'gamma': Real(1e-4, 1e+1, 'log-uniform'), \n",
    "    'epsilon': Real(0.01, 0.5, 'uniform') \n",
    "}\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "bayes_search_svr = BayesSearchCV(\n",
    "    estimator=SVR(kernel='rbf'),\n",
    "    search_spaces=search_spaces_svr,\n",
    "    n_iter=500,  \n",
    "    cv=tscv,\n",
    "    scoring='r2',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=1\n",
    ")\n",
    "bayes_search_svr.fit(X_train_scaled, y_train)\n",
    "print(f\"\\nCác tham số tốt nhất cho SVR: {bayes_search_svr.best_params_}\")\n",
    "best_svr_params = dict(bayes_search_svr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_svr = SVR(kernel='rbf', **best_svr_params)\n",
    "final_svr.fit(X_train_scaled, y_train)\n",
    "svr_preds = final_svr.predict(X_test_scaled)\n",
    "evaluate_model(y_test, svr_preds, \"SVR đã tinh chỉnh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1545459",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sns.scatterplot(x=y_test, y=svr_preds, ax=ax, alpha=0.6, label='Predicted')\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2, label='Line (y=x)')\n",
    "m, c = np.polyfit(y_test, svr_preds, 1)\n",
    "ax.plot(y_test, m * y_test + c, color='blue', linewidth=2, label=f'Fit Line: y={m:.2f}x + {c:.2f}')\n",
    "r2_value = r2_score(y_test, svr_preds)\n",
    "ax.lines[1].set_label(f'Fit Line (R²={r2_value:.2f})')\n",
    "ax.set_xlabel(\"Actual\", fontsize=12)\n",
    "ax.set_ylabel(\"Predicted\", fontsize=12)\n",
    "ax.set_title(\"Prediction results on the test set of model SVR\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e5fba6",
   "metadata": {},
   "source": [
    "### Stacking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcd6773",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw = df[features].iloc[:split_index], df[features].iloc[split_index:]\n",
    "y_train, y_test = df[target].iloc[:split_index], df[target].iloc[split_index:]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=features, index=X_train_raw.index)\n",
    "X_test = pd.DataFrame(X_test, columns=features, index=X_test_raw.index)\n",
    "\n",
    "base_models = {\n",
    "    'lgbm': lgb.LGBMRegressor(**best_lgbm_params, random_state=42),\n",
    "    'xgb': xgb.XGBRegressor(**best_xgb_params, random_state=42),\n",
    "    'rf': RandomForestRegressor(**best_rf_params, random_state=42),\n",
    "    'svr': SVR(kernel='rbf', **best_svr_params)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6a2a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "oof_predictions = {name: np.zeros(len(X_train)) for name in base_models.keys()}\n",
    "oof_indices = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(tscv.split(X_train)):\n",
    "    print(f\"Dang xu ly Fold {fold+1}/5\")\n",
    "    X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "    y_train_fold = y_train.iloc[train_idx]\n",
    "    for name, model in base_models.items():\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        preds = model.predict(X_val_fold)\n",
    "        oof_predictions[name][val_idx] = preds\n",
    "    oof_indices.extend(val_idx)\n",
    "    \n",
    "X_train_meta = pd.DataFrame(oof_predictions)\n",
    "unique_oof_indices = sorted(list(set(oof_indices)))\n",
    "X_train_meta = X_train_meta.iloc[unique_oof_indices]\n",
    "y_train_meta = y_train.iloc[unique_oof_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a095a386",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_model = RidgeCV()\n",
    "meta_model.fit(X_train_meta, y_train_meta)\n",
    "\n",
    "test_predictions = {}\n",
    "for name, model in base_models.items():\n",
    "    model.fit(X_train,y_train)\n",
    "    test_preds = model.predict(X_test)\n",
    "    test_predictions[name] = test_preds\n",
    "    \n",
    "X_test_meta = pd.DataFrame(test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c255b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = meta_model.predict(X_test_meta)\n",
    "evaluate_model(y_test, final_predictions, \"Stacking model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3157d34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "fig, ax = plt.subplots(figsize=(10,6))\n",
    "sns.scatterplot(x=y_test, y=final_predictions, ax=ax, alpha=0.6, label=\"Predicted\")\n",
    "ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], '--r', linewidth=2, label='Line (y=x)')\n",
    "m, c = np.polyfit(y_test, final_predictions, 1)\n",
    "ax.plot(y_test, m * y_test + c, color='blue', linewidth=2, label=f'Fit Line: y={m:.2f}x + {c:.2f}')\n",
    "r2_value = r2_score(y_test, final_predictions)\n",
    "ax.lines[1].set_label(f'Fit Line (R²={r2_value:.2f})')\n",
    "ax.set_xlabel(\"Actual\", fontsize=12)\n",
    "ax.set_ylabel(\"Predicted\", fontsize=12)\n",
    "ax.set_title(\"Prediction results on the test set of model Stacking\", fontsize=14)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
